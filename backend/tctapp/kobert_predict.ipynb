{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /Users/gungo/workspace/connect-project/backend/tctapp/.cache/kobert_v1.zip\n",
      "using cached model. /Users/gungo/workspace/connect-project/backend/tctapp/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/NLP/koBERTmodel_ver4.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 85\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m## 학습 모델 로드\u001B[39;00m\n\u001B[1;32m     84\u001B[0m PATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/content/drive/MyDrive/NLP/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 85\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPATH\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkoBERTmodel_ver4.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(PATH\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkoBERTmodelStateDict_ver4.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m#토큰화\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/connect-project/tct/lib/python3.9/site-packages/torch/serialization.py:771\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    769\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 771\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    773\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    774\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    775\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    776\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/workspace/connect-project/tct/lib/python3.9/site-packages/torch/serialization.py:270\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 270\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/workspace/connect-project/tct/lib/python3.9/site-packages/torch/serialization.py:251\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/NLP/koBERTmodel_ver4.pt'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "!pip install mxnet\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install transformers==3.0.2\n",
    "!pip install torch\n",
    "\n",
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
    "'''\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#BERT 모델, Vocabulary 불러오기 필수\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "# KoBERT에 입력될 데이터셋 정리\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))  \n",
    "\n",
    "# 모델 정의\n",
    "class BERTClassifier(nn.Module): ## 클래스를 상속\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=37,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n",
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 20\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n",
    "\n",
    "## 학습 모델 로드\n",
    "PATH = \"/content/drive/MyDrive/NLP/\"\n",
    "model = torch.load(PATH+\"koBERTmodel_ver4.pt\")\n",
    "model.load_state_dict(torch.load(PATH+\"koBERTmodelStateDict_ver4.pt\"))\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def new_softmax(a) : \n",
    "    c = np.max(a) # 최댓값\n",
    "    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = (exp_a / sum_exp_a) * 100\n",
    "    return np.round(y, 3)\n",
    "\n",
    "# 예측 모델 설정\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long()\n",
    "        segment_ids = segment_ids.long()\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long()\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            min_v = min(logits)\n",
    "            total = 0\n",
    "            probability = []\n",
    "            logits = np.round(new_softmax(logits), 3).tolist()\n",
    "            for logit in logits:\n",
    "                #print(logit)\n",
    "                probability.append(np.round(logit, 3))\n",
    "\n",
    "            if np.argmax(logits) == 0:  result = '신문, 언론, 저널리즘'\n",
    "            elif np.argmax(logits) == 1: result = '문헌정보학'\n",
    "            elif np.argmax(logits) == 2: result = '일반연속간행물'\n",
    "            elif np.argmax(logits) == 3: result = '일반학회, 단체, 협회, 기관'\n",
    "            elif np.argmax(logits) == 4: result = '총류'\n",
    "            elif np.argmax(logits) == 5: result = '철학'\n",
    "            elif np.argmax(logits) == 6: result = '형이상학'\n",
    "            elif np.argmax(logits) == 7: result = '심리학'\n",
    "            elif np.argmax(logits) == 8: result = '윤리학'\n",
    "            elif np.argmax(logits) == 9: result = '사회과학'\n",
    "            elif np.argmax(logits) == 10: result = '통계학'\n",
    "            elif np.argmax(logits) == 11: result = '경제학'\n",
    "            elif np.argmax(logits) == 12: result = '사회학, 사회문제'\n",
    "            elif np.argmax(logits) == 13: result = '정치학'\n",
    "            elif np.argmax(logits) == 14: result = '행정학'\n",
    "            elif np.argmax(logits) == 15: result = '법학'\n",
    "            elif np.argmax(logits) == 16: result = '교육학'\n",
    "            elif np.argmax(logits) == 17: result = '풍속, 민속학'\n",
    "            elif np.argmax(logits) == 18: result = '국방, 군사학'\n",
    "            elif np.argmax(logits) == 19: result = '지학'\n",
    "            elif np.argmax(logits) == 20: result = '광물학'\n",
    "            elif np.argmax(logits) == 21: result = '물리학'\n",
    "            elif np.argmax(logits) == 22: result = '공학, 공업일반'\n",
    "            elif np.argmax(logits) == 23: result = '예술'\n",
    "            elif np.argmax(logits) == 24: result = '문화'\n",
    "            elif np.argmax(logits) == 25: result = '건축술'\n",
    "            elif np.argmax(logits) == 26: result = '회화,도화'\n",
    "            elif np.argmax(logits) == 27: result = '오락, 운동'\n",
    "            elif np.argmax(logits) == 28: result = '연극'\n",
    "            elif np.argmax(logits) == 29: result = '음악'\n",
    "            elif np.argmax(logits) == 30: result = '독일어'\n",
    "            elif np.argmax(logits) == 31: result = '한국어'\n",
    "            elif np.argmax(logits) == 32: result = '문학'\n",
    "            elif np.argmax(logits) == 33: result = '한국문학'\n",
    "            elif np.argmax(logits) == 34: result = '영미문학'\n",
    "            elif np.argmax(logits) == 35: result = '역사'\n",
    "            elif np.argmax(logits) == 36: result = '아시아'\n",
    "\n",
    "            probability.append(result)\n",
    "            #print(probability)\n",
    "    return probability, result\n",
    "\n",
    "def category_sim(category):\n",
    "    if category == '신문, 언론, 저널리즘': prob_index = 0\n",
    "    elif category == '문헌정보학': prob_index = 1\n",
    "    elif category == '일반연속간행물': prob_index = 2\n",
    "    elif category == '일반학회, 단체, 협회, 기관': prob_index = 3\n",
    "    elif category == '총류': prob_index = 4\n",
    "    elif category == '철학': prob_index = 5\n",
    "    elif category == '형이상학': prob_index = 6\n",
    "    elif category == '심리학': prob_index = 7\n",
    "    elif category == '윤리학': prob_index = 8\n",
    "    elif category == '사회과학': prob_index = 9 \n",
    "    elif category == '통계학': prob_index = 10\n",
    "    elif category == '경제학': prob_index = 11\n",
    "    elif category == '사회학, 사회문제': prob_index = 12\n",
    "    elif category == '정치학': prob_index = 13\n",
    "    elif category == '행정학': prob_index = 14\n",
    "    elif category == '법학': prob_index = 15\n",
    "    elif category == '교육학': prob_index = 16\n",
    "    elif category == '풍속, 민속학': prob_index = 17\n",
    "    elif category == '국방, 군사학': prob_index = 18\n",
    "    elif category == '지학': prob_index = 19\n",
    "    elif category == '광물학': prob_index = 20\n",
    "    elif category == '물리학': prob_index = 21\n",
    "    elif category == '공학, 공업일반': prob_index = 22\n",
    "    elif category == '예술': prob_index = 23\n",
    "    elif category == '문화': prob_index = 24\n",
    "    elif category == '건축술': prob_index = 25\n",
    "    elif category == '회화,도화': prob_index = 26\n",
    "    elif category == '오락, 운동': prob_index = 27\n",
    "    elif category == '연극': prob_index = 28\n",
    "    elif category == '음악': prob_index = 29\n",
    "    elif category == '독일어': prob_index = 30\n",
    "    elif category == '한국어': prob_index = 31\n",
    "    elif category == '문학': prob_index = 32\n",
    "    elif category == '한국문학': prob_index = 33\n",
    "    elif category == '영미문학': prob_index = 34\n",
    "    elif category == '역사': prob_index = 35\n",
    "    elif category == '아시아': prob_index = 36\n",
    "    return prob_index\n",
    "\n",
    "model_prob, model_result = predict(input)\n",
    "print(model_result)\n",
    "\n",
    "model_prob_index = category_sim(model_result)\n",
    "print(model_prob[model_prob_index]) #모델이 예측한 결과에 대한 확률\n",
    "\n",
    "input_topic = \"\"  #사용자가 입력한 주제\n",
    "user_prob_index = category_sim(input_topic)\n",
    "print(model_prob[user_prob_index]) #사용자가 입력한 주제에 대한 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc22cc256e5c39c0fcbeedf1ae89f7db5ebbec427b80b1d256637f00845497e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}